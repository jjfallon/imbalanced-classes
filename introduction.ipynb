{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imbalanced classes â€” introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In classification you are trying to split data into a number of discrete classes. This works very well if there are equal number of training examples for the different classes but can fall down if one class dominates. In the extreme case when your classifier might always predict the most frequently occuring class. If pure prediction is the goal this can be the correct thing to do, but it could be the case that the infrequent occuring class is more important to you (for example, customers who spend the most might be rarer for a company but more important for the company's business model).\n",
    "\n",
    "As Provost (_Machine Learning from Imbalanced Data Sets 101_)<sup>[1]</sup> describes it,\n",
    ">The assumptions built into (most of) these algorithms are: \n",
    "> 1. that maximizing accuracy is the goal, and \n",
    "> 2. that,  in  use, the  classifier  will  operate  on  data  drawn  from the same distribution as the training data.\n",
    "\n",
    "This second point is important when, for example, the data you use for training is imblanaced but you expect the live system to be running on more balanced data. These assumptions can be valid so you need to think carefully about whether having imbalanced classes is an issue in any given scenario. Is overall accuracy the goal or do you care equally about accurately predicting different classes?\n",
    "\n",
    "Most presentations of dealing with imbalanced data assume you do care equally about the two cases, however you might care more amount one class. Continuing the example from above, high spenders at your business might represent 10% of your data but they may account for 90% of revenues. In this case you might not care equally about whether your model is good for low spenders as opposed to high spenders. In one of the sections below _Cost Sensitive Classification_ is discussed which does allow you to specify the costs associated with misclassifying different classes, but the majority of the presentation here will focus on the case where you care equally about the different classes.\n",
    "\n",
    "The degree that one class dominates the other is not the sole determination of the impact of class imbalance. Class imbalance is likely to be more of a problem for small samples as there is less information (because of fewer data points) abother the minority class. Another factor is the degree of overlap between classes; for a fixed ratio of classes, having well separate classes should result in better results. An additional complication is the degree of homogenity in the classes, you could have very distinct classes (dogs _vs._ cats) or one class might be very broad (dogs _vs._ other animals).\n",
    "\n",
    "[1]:http://pages.stern.nyu.edu/~fprovost/Papers/skew.PDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Terminology\n",
    "\n",
    "On terminology, when you are building a model to distinguish between two class this is called _binomial classification_ (typically the class are labelled 1 and 0), and if there are more than two classes it is sometimes called multinomial classification and sometimes multiclass classification.\n",
    "\n",
    "For binomial classification, when the class is imbalanced the class appearing less frequently is known as the minority class (typically labelled 1) and the more frequently appearing class is known as the majority class (typically labelled 0).\n",
    "\n",
    "The techniques shown in these notebooks can be used for both binomial and multinomial classification but the examples shown are all binomial for brevity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from imblearn.datasets import make_imbalance\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.datasets import make_moons\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Define a function for plotting data.\n",
    "def plot_data(X, y):\n",
    "    plt.scatter(X[y == 0, 0], X[y == 0, 1], alpha=0.5)\n",
    "    plt.scatter(X[y == 1, 0], X[y == 1, 1], alpha=0.5)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To demonstrate class imbalance let's first create and visualise some imbalanced data. This way of building an imbalanced class is based on an example given in the _imbalanced-learn_ package documentation (http://contrib.scikit-learn.org/imbalanced-learn/). Here the data has two classes, with the minority class appearing 15% of the time. The same example will be used throughout these notebooks for consistency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX8AAAD8CAYAAACfF6SlAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQUT8BUEQepD/HyiEPWcE0OcnAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f18415add90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X, y = make_moons(n_samples=500, shuffle=True, noise=0.4, random_state=40)\n",
    "X_, y_ = make_imbalance(X, y, ratio=0.15, min_c_=1, random_state=40)\n",
    "\n",
    "# Plot the imbalanced data\n",
    "plot_data(X_, y_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then a simple support vector machine (SVM) classifier can be fitted to it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.91      1.00      0.95        83\n",
      "          1       1.00      0.33      0.50        12\n",
      "\n",
      "avg / total       0.92      0.92      0.90        95\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_, y_, test_size=0.33, stratify=y_, random_state=40 )\n",
    "\n",
    "# Fit svm model\n",
    "model = SVC(random_state=40, probability=True)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_predict = model.predict(X_test)\n",
    "\n",
    "# Assess the predictive power\n",
    "print classification_report(y_test, y_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This classification report shows that whilst the model is good at accurately predicting the majority class it is not good at predicting the minority class. This also shows that if all classes are important to you, looking at metrics such as the f1-score is more important than a pure accuracy score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Measuring efficacy\n",
    "\n",
    "As discussed at the start, one of the assumptions behind classifiers such as the SVM above is that overall accuracy should be minimised. Where accuracy is simplier the proportion of predictions (on the test data) turn out to be correct.\n",
    "\n",
    "If we do consider accuracy (the proportion of predictions that are correct) we get:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.915789473684\n"
     ]
    }
   ],
   "source": [
    "print accuracy_score(y_test, model.predict(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model is doing well but the classifcation report above shows that predictions for the minority class are far from perfect. Looking at precision and recall gives more insight into the data, and f1-score takes more notice of performance on the different classes (as does area under the ROC curve). If the different classes are equally  important to you, f1-score would be worth using to evaluate the model.\n",
    "\n",
    "If f1-score is more informative why doesn't the model minimise it during fitting? The answer is that using f1-score would not result in a convex cost function, and optimisers for convex problems are very well developed (and performant) so most models only implement convex cost functions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Taxonomies\n",
    "\n",
    "Approaches to tackling imbalances can be catagorised in many different ways. Typically they are catagorised in terms of what you do practically, and for example in the introduction of the paper by Cruz _et al._ (_Tackling Class Imbalance with Ranking_)<sup>[2]</sup> they define the following four catagories:\n",
    "\n",
    ">**1. Pre-processing** step  changing  the  class  priors  by  under-sampling the majority class and/or creating new synthetic examples of the minority class, or even changing class priors by changing class labels themselves (e.g. MetaCost);\n",
    "\n",
    ">**2. Training with costs** instead of maximizing accuracy, the training algorithm maximizes weighted accuracy, so that the cost of misclassifying a class is inversely proportional to its frequency;\n",
    "\n",
    ">**3. Post-processing** by  tweaking  the  decision  boundary  by such  measures  as  changing  a  threshold  after  which  one\n",
    "class is selected, sometimes with the aid of a ROC curve;\n",
    "\n",
    ">**4. Ensembles** by which each model within the ensemble is trained  with  balanced  subsets  of  the  data,  coupled with the previous preprocessing techniques.\n",
    "\n",
    "The paper itself is focused on re-casting the problem as a ranking problem, and also mentions in passing that in some circumstances you can re-cast the problem to be that of anomaly detection.\n",
    "\n",
    "Ling _et al._ (_Cost Sensitive Learning and the Class Imbalance Problem_)<sup>[3]</sup> provide a different breakdown based more on a theoretical look at class imbalance which shows that there are sounds reasons to tweak probabily thresholds and other techniques (such as MetaCost) are also based around probability thresholds. \n",
    "\n",
    "[2]:http://vcmi.inescporto.pt/reproducible_research/ijcnn2016/ClassImbalance/imbalance.pdf\n",
    "[3]:http://www.csd.uwo.ca/faculty/ling/papers/cost_sensitive.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cost of classification\n",
    "\n",
    "At the heart of a lot of approaches to dealing with imbalanced classes is the idea of the cost of (mis)classification (Ling _et al._ <sup>[3]</sup> provide a good discussion as does Elkan<sup>[4]</sup>). The idea is that classifing a sample (a particular data point) as being in class 0 when it really is class 1 might have a different impact (have a different _cost_) than classifing sample $x_1$ as class 1 when it really is class 0. The cost of classifying a sample as class $i$ when it actually belongs to class $j$ is written as:\n",
    "$$c_{ij}$$\n",
    "Interestingly, for the multinomial case, this cost can vary depending on what incorrect class is suggested (not all misclassifications are equal). Also, you still specify \"costs\" for correct classifications ($c_{ii}$) though these can be thought of as benefits.\n",
    "\n",
    "Following the notation used by Ling _et al._, the expected cost ($R$) of classifying sample $x$ as class $i$ can be written as:\n",
    "\n",
    "$$ R\\left( i \\mid x\\right) = \\sum_{j} P\\left( j \\mid x\\right) c_{ij} $$\n",
    "where $P\\left( j \\mid x\\right)$ is the probability that $x$ belongs to class $j$. (Note, the cost/benefit of correct classification, $c_{ii}$, will often be zero.) The principle behing a lot of techniques is to minimise this expected cost. \n",
    "\n",
    "These costs can encode our known preferences for different classes. In the case of caring equally about making accurate predictions for two different classes we want the cost of incorrectly labelling an example from the minority class as being from the majority class ($c_{01}$) is $n$ times greater than labelling an example from the majority class as being in the minority class ($c_{10}$), where $n$ is the ratio of the number of samples in the majority class to the number in the minority class.\n",
    "\n",
    "Many techniques for dealing with imbalanced data are based upon these ideas. Post-processing results via the use of thresholds is probably the most direct application of this idea, followed by training with costs. These two approaches are quick to apply so are demonstrated below rather than in their own notebooks.\n",
    "\n",
    "[3]:http://www.csd.uwo.ca/faculty/ling/papers/cost_sensitive.pdf\n",
    "[4]:https://pdfs.semanticscholar.org/2402/9028c1b280c7e62491999824853212ae148c.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Post-processing results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The idea of post-processing the results is that instead of balancing the input data or tweaking the model to account for the imbalances you instead apply a processing step to the outputs of the model.\n",
    "\n",
    "Most classification models output the probability that a given data point belongs to each class. A data point is predicted to belong the most probable class. For two class problems here is only really one indepentent probability (since the probabilites sum to one), so instead this process can be thought of as assigning a data point to the minority class if the probability of belonging to it is greater than a threshold value, which by default is taken to be 0.5 (the logical value) but for imbalanced data is often taken to be an additional hyperparameter. Is this approach justified?\n",
    "\n",
    "Yes. If we think of the problem as one of cost sensitive classification we should be assigning the data point to the class that produces the lowest cost of classification, rather than the most probable class.\n",
    "\n",
    "For the two class system you would choose class 1 if:\n",
    "\n",
    "$$ R\\left( 1 \\mid x\\right) < R\\left( 0 \\mid x\\right) $$\n",
    "\n",
    "which can be written as:\n",
    "\n",
    "$$ P\\left( 1 \\mid x\\right) > \\frac{c_{10}}{c_{10} + c_{01}} $$\n",
    "\n",
    "In effect minimising the expected cost of classification can be thought of as applying a different probability threshold.\n",
    "\n",
    "For the example considered here, if we care equally about the two classes then the threshold would be:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1289198606271777"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c01_c10 = (y_==0).sum() / (y_==1).sum()\n",
    "\n",
    "threshold = 1 / (1 + c01_c10)\n",
    "\n",
    "threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.90      0.95        83\n",
      "          1       0.60      1.00      0.75        12\n",
      "\n",
      "avg / total       0.95      0.92      0.92        95\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def make_prediction(data, model, threshold):\n",
    "    probs = model.predict_proba(data)\n",
    "    return [1 if prob[1] > threshold else 0 for prob in probs]\n",
    "\n",
    "y_predict = make_prediction(X_test, model, threshold)\n",
    "print classification_report(y_test, y_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This has led to a substanially improvement in the minority class predictions and a small improvement in the majority class prediction.\n",
    "\n",
    "This has shown that ddjusting the probability threshold does have a solid theoretical basis, though in practice this is often tuned as a hyperparameter rather than dervived as above. The assumption being made is that the trained model is producing accurate probabilities, _i.e._ information about the minority class is correctly being captured. You can imagine scenarios where the model ignores the information from the minority class when training so that the output probabilities are not accurate enough."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training with costs\n",
    "\n",
    "Many algorithms allow you to specify class weights. These are used internally, alogorithms are alterted so that larger penalties are attached to classes with higher weights. The algorithm is then taking the costs of classification into account when fitting the data.\n",
    "\n",
    "For example with the SVM from before we just make a very simple change:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.75      0.86        83\n",
      "          1       0.36      1.00      0.53        12\n",
      "\n",
      "avg / total       0.92      0.78      0.81        95\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = SVC(random_state=40, probability=True, class_weight='balanced')\n",
    "model.fit(X_train, y_train)\n",
    "y_predict = model.predict(X_test)\n",
    "\n",
    "print classification_report(y_test, y_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and get poorer results overall (due to a fall in the majority class predictions) but a small improvement in the minority class predictions. Depending on the exact dataset, training with costs can outperform applying a threshold.\n",
    "\n",
    "Whilst (atleast in _sklearn_) the syntax for specifying weights is common across alot of different techniques, internally the weights are used in different ways. One way in which decisions trees use weights was outlined in Ting's paper _An Instance-Weight Method to Induce Cost-Sensitive Trees_<sup>5</sup> where the criteria for judging where to split the tree is altered to give more weight to the classes with larger weight.\n",
    "\n",
    "[5]:http://sci2s.ugr.es/keel/pdf/algorithm/articulo/2002%20-%20Ting%20-%20An%20instance-weighting%20method%20to%20induce%20cost-sensitive%20trees%20-%20IEEETKDE.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Note\n",
    "\n",
    "The examples here are designed to be illustrations of possible approaches, they are not designed as a benchmark. Not only is the example not representative of classification challenges that you may experience in the wild, hyperparameter tuning has largely been ignored. Different approaches are likely to have different optimal values of the hyperparameters, using optimal values for each model could result in a very different picture of optimal performance. \n",
    "\n",
    "Nevertheless this does show that there is merit in all of these approaches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
